{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import geopy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "property_files = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{property_files}curated/past_listing.csv')\n",
    "# print the size (length) of datasets to have a rough idea about \n",
    "# how much data are dropped each time\n",
    "print(len(df))\n",
    "df = df.rename(columns={'code': 'postcode'}, errors=\"coerce\")\n",
    "# the record must be listed more than once\n",
    "# as we want to predict the future price using past listing data\n",
    "df = df[df.groupby('address').address.transform('count') > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read in the postcode information\n",
    "postcode_df = pd.read_csv('../data/raw/abs/australian_postcodes.csv')\n",
    "# only retain information that is relavent for faster running time\n",
    "postcode_df = postcode_df.loc[postcode_df['state'] == 'VIC']\n",
    "postcode_df = postcode_df[['postcode', 'lgaregion']]\n",
    "df = pd.merge(df, postcode_df, on='postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# a list of meltropolitan melbourne LGA that is defined by the Victorian government\n",
    "metro_melb = ['Banyule', 'Bayside', 'Boroondara', 'Brimbank', 'Cardinia', 'Casey', 'Darebin', 'Frankston', 'Glen Eira',\n",
    "              'Greater Dandenong', 'Hobsons Bay', 'Hume', 'Kingston', 'Knox', 'Manningham', 'Maribyrnong', 'Maroondah',\n",
    "              'Melbourne', 'Melton', 'Monash', 'Moonee Valley', 'Moreland', 'Mornington Peninsula', 'Nillumbik',\n",
    "              'Port Phillip', 'Stonnington', 'Whitehorse', 'Whittlesea', 'Wyndham', 'Yarra', 'Yarra Ranges']\n",
    "# only retain records that are in Meltropolitan Melbourne\n",
    "df = df.loc[df['lgaregion'].isin(metro_melb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check again how many records are left\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# consider there are still a lot of entries and restricted API usage\n",
    "# we only use entries with fairly recent records, namely properties \n",
    "# that have been listed in 2022 and 2021\n",
    "addresses = df.loc[df['year'] == 2022]['address'].tolist()\n",
    "addresses = df.loc[df['year'] == 2021]['address'].tolist() + addresses\n",
    "# this deduplicate the records\n",
    "# for example a property listed three times will have three rows \n",
    "# deduplication will make sure they only exist in the list once\n",
    "addresses = list(set(addresses))\n",
    "# check the number of addresses are going to be geocoded\n",
    "len(addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode_df\n",
    "geocode_df = []\n",
    "coded_l = []\n",
    "# coded_l = geocode_df.address.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# as there is a request limit of 1 request per second for Nominatim API\n",
    "# considering the large size of data, the estimated run time would be multiple days\n",
    "# hence, we need to cache responses\n",
    "# this chunck is reading the response from API\n",
    "if os.path.exists(f'{property_files}raw/geo.csv'):\n",
    "    df2 = pd.read_csv(f'{property_files}raw/geo.csv').iloc[: , 1:]\n",
    "    temp = []\n",
    "    addresses_saved = df2['address'].tolist()\n",
    "    # remove the addresses that have been requested\n",
    "    for i in tqdm(addresses):\n",
    "        if i not in addresses_saved:\n",
    "            temp.append(i)\n",
    "    addresses = temp\n",
    "    len(addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# request geocode for each address\n",
    "count = 0;\n",
    "geo_data = []\n",
    "for address in tqdm(addresses):\n",
    "    locator = geopy.Nominatim(user_agent=\"myGeocoder\");\n",
    "    location = locator.geocode(address+\", VICTORIA\",timeout=None);\n",
    "    if location != None:\n",
    "        info = [address, location.address, location.latitude, location.longitude]\n",
    "        # save response into a list\n",
    "        geo_data.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(f'{property_files}raw/geo.csv'):\n",
    "    # merge with previously response\n",
    "    df2 = df2.append(pd.DataFrame(geo_data, columns = df2.columns))\n",
    "else:\n",
    "    # or cache the response as a dataframe\n",
    "    df2 = pd.DataFrame(geo_data, columns = ['address', 'loc_address', 'lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# preview the result\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save/cache result to a csv file \n",
    "df2.to_csv(f'{property_files}/raw/geo.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
